\documentclass[a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[portuguese]{babel}
\usepackage{hyperref}
\usepackage{a4wide}
\hypersetup{pdftitle={PCP - OpenMP},
pdfauthor={João Teixeira, José Ferreira},
colorlinks=true,
urlcolor=blue,
linkcolor=black}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{appendix}
\usepackage{tikz}
\usepackage{authblk}
\usepackage{bashful}
\usepackage{verbatim}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{mwe}
\usepackage[parfill]{parskip}
\usetikzlibrary{positioning,automata,decorations.markings}
\AfterEndEnvironment{figure}{\noindent\ignorespaces}
\AfterEndEnvironment{table}{\noindent\ignorespaces}

\begin{document}

\title{Paradigmas de Computação Paralela\\Bucket Sort com OpenMP}
\author{João Teixeira (A85504) \and José Filipe Ferreira (A83683)}
\date{\today}

\begin{center}
    \begin{minipage}{0.75\linewidth}
        \centering
        \includegraphics[width=0.4\textwidth]{images/eng.jpeg}\par\vspace{1cm}
        \vspace{1.5cm}
        \href{https://www.uminho.pt/PT}
        {\color{black}{\scshape\LARGE Universidade do Minho}} \par
        \vspace{1cm}
        \href{https://www.di.uminho.pt/}
        {\color{black}{\scshape\Large Departamento de Informática}} \par
        \vspace{1.5cm}
        \maketitle
    \end{minipage}
\end{center}

\tableofcontents

\pagebreak

\chapter{Introdução}
O algoritmo escolhido para o projeto da unidade curricular de Computação
Paralela e Distribuída foi o \textit{Bucket Sort}.

Inicialmente desenvolvemos uma versão sequencial do projeto e procedemos ao
\textit{benchmarking} do programa resultante. Em seguida convertemos a
implementação sequencial numa versão com utilização de memoria partilhada
fazendo uso de \textit{OpenMP} e comparamos o resultado com a versão sequencial
desenvolvida anteriormente.

Ao longo deste relatório iremos descrever a metodologia utilizada e os
resultados de \textit{benchmarking} obtidos ao longo deste projeto.

\chapter{Sequencial}
O \textit{Bucket Sort} consiste em definir um conjunto de N "baldes"
inicialmente vazios. Em seguida os elementos do vetor a ser ordenado são
distribuídos pelos baldes. O critério escolhido para esta distribuição foi
calcular o máximo e o mínimo do vetor a ser ordenado e dividir os intervalos de
valores de cada balde em intervalos do mesmo tamanho. Os elementos do vetor
inicial são então distribuídos pelo respetivo balde com base no intervalo
definido. Seguidamente o conteúdo de cada balde é ordenado recorrendo ao
\textit{quicksort} presente na \textit{standard library} de C. Finalmente todos
os elementos são copiados um a um para o vetor original.

Para testar se a primeira implementação sequencial produzia de facto vetores
ordenados criamos um \textit{script} que permite gerar N testes aleatórios e
comparar o resultado do nosso programa com o resultado de ordenar os valores
com o comando \textit{sort} de \textit{bash}.

Numa implementação inicial desta versão sequencial, o algoritmo consistia em
iterar sobre o array dos elementos a ordenar e inserir o elemento a processar no
respetivo balde. Durante a paralelização deste, identificamos alguns problemas,
que serão descritos em maior pormenor no capitulo \ref{chap:omp}, que nos levou
a tomar uma abordagem diferente, em vez de iterar pelo array uma vez e colocar
os elementos no respetivo balde, cada balde irá iterar pelo array, escolhendo os
elementos que a ele lhe pertencem.

Fazer isto aumentou a complexidade do algoritmo, passando de iterar uma vez pelo
array, para N vezes, onde N é o número de baldes existentes. Como
consequência disto
também os tempos de execução aumentarem.

TODO: INSERIR BENCHAMRKS

\chapter{OpenMP} \label{chap:omp}
Fazendo uso da implementação sequencial descrita no capitulo anterior, começamos
a conversão para uma versão com um modelo de memoria partilhada fazendo uso de
\textit{OpenMP}.

Para a paralelização da primeira versão sequencial, começamos por tratar do
ciclo mais longo que itera por todos os elementos do \textit{array}. Ao fazer
uma analise mais detalhada deste, deparamo-nos com a existência de uma zona
critica onde era escrito cada elemento no respetivo balde. Para tentar resolver
o problema tentamos duas abordagens distintas, a utilização de tarefas e a
declaração da zona critica. Em ambas as opções obtivemos resultados piores
quando comparados com a sua versão sequencial, pois tanto a gestão de zonas
criticas, bem como a gestão das tarefas são tarefas pesadas.

Vendo estes resultados, tentamos adaptar o algoritmo para um formato mais
paralelizável, removendo a zona critica.

Nesta nova versão verificamos que os tempos de execução paralelos estavam a
baixar, obtendo speedups consideráveis até às 16 \textit{threads}. Embora o
speedup esteja ligeiramente abaixo do ideal e se afastar do valor quanto maior o
numero de \textit{threads}. Isto deve-se ao número de elementos por balde não
ser uniforme e o tempo de execução só conseguir ser tão baixo quanto o balde
mais lento de processar. Por isso, quanto maior o numero de \textit{threads} em
trabalho mais se notará esse desiquelibrio.

Para tentar mitigar este problema tentamos utilizar o colapsamento dos dois
ciclos aninhados, o que percorre os baldes e o interior que percorre o array dos
elementos. Para manter a escrita no balde dos elementos em paralelo a
atualização do índice de escrita no balde era feita de forma atómica. Nesta
implementação, a escalabilidade do algoritmo provou-se bastante inferior,
começando a diminuir a partir das 4 threads.

TODO: INSERIR BENCHAMRKS

\end{document}
